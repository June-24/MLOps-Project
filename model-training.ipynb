{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36e74fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, confusion_matrix, classification_report, matthews_corrcoef)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37ce50df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test the model\n",
    "def train_model(X_train, y_train, X_test, y_test, feature_names):\n",
    "    # Initialize and fit the model\n",
    "    done_model = RandomForestClassifier(\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "        n_estimators=100, #try 50 # was 100\n",
    "        #max_depth = 10, #default is none\n",
    "        #max_features=3, # Fewer features per split, less memory\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    done_model.fit(X_train, y_train)\n",
    "\n",
    "    # Test predictions\n",
    "    y_pred = done_model.predict(X_test)\n",
    "\n",
    "    # Evaluate model\n",
    "    metrics_rf = calculate_performance_metrics(y_test, y_pred)\n",
    "    print_performance_metrics(metrics_rf)\n",
    "    feature_importance(done_model, X_train, feature_names)\n",
    "\n",
    "    return done_model\n",
    "\n",
    "# Useful values for classification\n",
    "def calculate_performance_metrics(y_test, y_pred):\n",
    "    metrics = {}\n",
    "    metrics['accuracy'] = accuracy_score(y_test, y_pred)\n",
    "    metrics['precision'] = precision_score(y_test, y_pred, average='weighted')\n",
    "    metrics['recall'] = recall_score(y_test, y_pred, average='weighted')\n",
    "    metrics['f1_score'] = f1_score(y_test, y_pred, average='weighted')\n",
    "    metrics['confusion_matrix'] = confusion_matrix(y_test, y_pred)\n",
    "    metrics['mcc'] = matthews_corrcoef(y_test, y_pred)\n",
    "    metrics['classification_report'] = classification_report(y_test, y_pred)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Prints all performance metrics\n",
    "def print_performance_metrics(metrics):\n",
    "    print(\"Accuracy:\", metrics.get('accuracy', \"Not computed\"))\n",
    "    print(\"Precision:\", metrics.get('precision', \"Not computed\"))\n",
    "    print(\"Recall:\", metrics.get('recall', \"Not computed\"))\n",
    "    print(\"F1 Score:\", metrics.get('f1_score', \"Not computed\"))\n",
    "    print(\"Confusion Matrix:\\n\", metrics.get('confusion_matrix', \"Not computed\"))\n",
    "    print(\"Matthews Correlation Coefficient (MCC):\", metrics.get('mcc', \"Not computed\"))\n",
    "    print(\"Classification Report:\\n\", metrics.get('classification_report', \"Not computed\"))\n",
    "\n",
    "# Determine the feature importance in the model\n",
    "def feature_importance(model, X, feature_names):\n",
    "    feature_importances = model.feature_importances_\n",
    "    feature_importances_list = [(feature_names[j], importance) for j, importance in enumerate(feature_importances)]\n",
    "    feature_importances_list.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"Feature Importances:\")\n",
    "    for feature, importance in feature_importances_list:\n",
    "        print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b37816b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains the model\n",
    "def create_model():\n",
    "    # Load the data\n",
    "    data_name = ''\n",
    "    processed_data = pd.read_csv(\"./data/final.csv\")\n",
    "    processed_data = processed_data.drop(columns=[\"time\"])\n",
    "\n",
    "\n",
    "    # Separate data\n",
    "    target_name = 'weather_code (wmo code)'\n",
    "    X = processed_data.drop(columns=[target_name]).values\n",
    "    y = processed_data[target_name].values\n",
    "\n",
    "    # feature_names = processed_data.columns[:-1].tolist()\n",
    "    feature_names = processed_data.drop(columns=[target_name]).columns.tolist()\n",
    "\n",
    "    # Get test and train\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    print('Read the data')\n",
    "    # Run the model\n",
    "    model = train_model(X_train, y_train, X_test, y_test, feature_names)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f0ded18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read the data\n",
      "Accuracy: 0.8323170731707317\n",
      "Precision: 0.8173265227370853\n",
      "Recall: 0.8323170731707317\n",
      "F1 Score: 0.8073540194211812\n",
      "Confusion Matrix:\n",
      " [[ 40   0   0   1   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  6   2   3   1   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  2   0   9   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 166   0   0   0   0   0   0   0   0   2   0   0]\n",
      " [  0   0   0   5   2   3   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   3   1   1   0   0   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0  19   0   0   1   0   0   1   0   0]\n",
      " [  0   0   0   0   0   0   2   5   0   1   0   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0   1   0   0   0   0   0   0   0]\n",
      " [  0   0   0   3   0   0   0   0   0   7   0   0   2   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   0   2   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   3   0   0   3]\n",
      " [  0   0   0   2   0   0   0   1   0   1   0   0  15   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   2   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   3   0   0   4]]\n",
      "Matthews Correlation Coefficient (MCC): 0.7581028605780907\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89        41\n",
      "           1       1.00      0.17      0.29        12\n",
      "           2       0.75      0.82      0.78        11\n",
      "           3       0.92      0.99      0.95       168\n",
      "          45       0.67      0.20      0.31        10\n",
      "          48       0.25      0.20      0.22         5\n",
      "          51       0.90      0.86      0.88        22\n",
      "          53       0.71      0.56      0.62         9\n",
      "          55       0.00      0.00      0.00         1\n",
      "          61       0.64      0.58      0.61        12\n",
      "          63       0.00      0.00      0.00         3\n",
      "          71       0.50      0.50      0.50         6\n",
      "          80       0.60      0.79      0.68        19\n",
      "          81       0.00      0.00      0.00         2\n",
      "          85       0.57      0.57      0.57         7\n",
      "\n",
      "    accuracy                           0.83       328\n",
      "   macro avg       0.56      0.48      0.49       328\n",
      "weighted avg       0.82      0.83      0.81       328\n",
      "\n",
      "Feature Importances:\n",
      "cloud_cover_mean (%): 0.12061396265301869\n",
      "cloud_cover_max (%): 0.1161380322630303\n",
      "precipitation_sum (mm): 0.07500032560271502\n",
      "precipitation_hours (h): 0.0586048825300175\n",
      "showers_sum (mm): 0.054951441068951216\n",
      "rain_sum (mm): 0.04238111825557884\n",
      "relative_humidity_2m_max (%): 0.027837904946427558\n",
      "year: 0.02427694516991595\n",
      "sunshine_duration (s): 0.017882562247584926\n",
      "relative_humidity_2m_mean (%): 0.017840902719045516\n",
      "visibility_min (m): 0.015139756635786771\n",
      "dew_point_2m_min (°C): 0.013331688642854873\n",
      "dew_point_2m_max (°C): 0.013230385393700838\n",
      "dew_point_2m_mean (°C): 0.012356296507157397\n",
      "visibility_mean (m): 0.012193985906904316\n",
      "apparent_temperature_mean (°C): 0.012001523536779754\n",
      "relative_humidity_2m_min (%): 0.011849128182006159\n",
      "shortwave_radiation_sum (MJ/m²): 0.011725858976050598\n",
      "et0_fao_evapotranspiration_sum (mm): 0.010826687115271306\n",
      "vapour_pressure_deficit_max (kPa): 0.010702179982430508\n",
      "wet_bulb_temperature_2m_mean (°C): 0.01034169410394743\n",
      "wet_bulb_temperature_2m_min (°C): 0.010222122850557546\n",
      "wind_gusts_10m_min (km/h): 0.010210585576360601\n",
      "temperature_2m_min (°C): 0.010155141950510224\n",
      "apparent_temperature_min (°C): 0.010145204282096205\n",
      "et0_fao_evapotranspiration (mm): 0.010062817185390573\n",
      "soil_moisture_0_to_10cm_mean (m³/m³): 0.009675725489241721\n",
      "wind_speed_10m_mean (km/h): 0.009542809867635497\n",
      "daylight_duration (s): 0.009505121297995965\n",
      "uv_index_max (): 0.0094186946223074\n",
      "temperature_2m_mean (°C): 0.009254711159731668\n",
      "wind_speed_10m_max (km/h): 0.009252716365353977\n",
      "wind_gusts_10m_max (km/h): 0.009217749706947866\n",
      "wet_bulb_temperature_2m_max (°C): 0.009204833862182191\n",
      "wind_gusts_10m_mean (km/h): 0.009179907822925814\n",
      "wind_direction_10m_dominant (°): 0.009158911621053291\n",
      "snowfall_water_equivalent_sum (mm): 0.009150113623772941\n",
      "winddirection_10m_dominant (°): 0.00906809663626487\n",
      "cape_mean (J/kg): 0.00897252247711769\n",
      "cloud_cover_min (%): 0.008912623562687816\n",
      "temperature_2m_max (°C): 0.008464570271200835\n",
      "year_cos: 0.008062325601451542\n",
      "pressure_msl_mean (hPa): 0.007909930874118083\n",
      "surface_pressure_min (hPa): 0.007904164701156475\n",
      "snowfall_sum (cm): 0.007848323338849826\n",
      "day_of_year: 0.007775885080999564\n",
      "apparent_temperature_max (°C): 0.007568958125062645\n",
      "pressure_msl_max (hPa): 0.0074125185206082335\n",
      "surface_pressure_max (hPa): 0.007338031014541117\n",
      "day_of_month: 0.007277920185486956\n",
      "year_sin: 0.007200505425271628\n",
      "surface_pressure_mean (hPa): 0.006958756483882155\n",
      "wind_speed_10m_min (km/h): 0.006918248778733396\n",
      "pressure_msl_min (hPa): 0.006608894049479067\n",
      "uv_index_clear_sky_max (): 0.006132398739165105\n",
      "cape_max (J/kg): 0.00554372810977749\n",
      "day_of_week: 0.004333017161968417\n",
      "month: 0.0033515928227526403\n",
      "month_sin: 0.0030013373561318534\n",
      "month_cos: 0.002077323769563921\n",
      "cape_min (J/kg): 0.0006821088238546823\n",
      "visibility_max (m): 9.178836663511883e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "/mnt/c/Users/Moham/OneDrive/Documents/GitHub/MLOps-Project/ENV/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/mnt/c/Users/Moham/OneDrive/Documents/GitHub/MLOps-Project/ENV/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/mnt/c/Users/Moham/OneDrive/Documents/GitHub/MLOps-Project/ENV/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/mnt/c/Users/Moham/OneDrive/Documents/GitHub/MLOps-Project/ENV/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Runs the model\n",
    "def run_model_training():\n",
    "    # Train the model\n",
    "    create_model()\n",
    "\n",
    "run_model_training()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
