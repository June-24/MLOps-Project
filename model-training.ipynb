{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36e74fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, confusion_matrix, classification_report, matthews_corrcoef)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37ce50df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test the model\n",
    "def train_model(X_train, y_train, X_test, y_test, feature_names):\n",
    "    # Initialize and fit the model\n",
    "    done_model = RandomForestClassifier(\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "        n_estimators=100, #try 50 # was 100\n",
    "        #max_depth = 10, #default is none\n",
    "        #max_features=3, # Fewer features per split, less memory\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    done_model.fit(X_train, y_train)\n",
    "\n",
    "    # Test predictions\n",
    "    y_pred = done_model.predict(X_test)\n",
    "\n",
    "    # Evaluate model\n",
    "    metrics_rf = calculate_performance_metrics(y_test, y_pred)\n",
    "    print_performance_metrics(metrics_rf)\n",
    "    feature_importance(done_model, X_train, feature_names)\n",
    "\n",
    "    return done_model\n",
    "\n",
    "# Useful values for classification\n",
    "def calculate_performance_metrics(y_test, y_pred):\n",
    "    metrics = {}\n",
    "    metrics['accuracy'] = accuracy_score(y_test, y_pred)\n",
    "    metrics['precision'] = precision_score(y_test, y_pred, average='weighted')\n",
    "    metrics['recall'] = recall_score(y_test, y_pred, average='weighted')\n",
    "    metrics['f1_score'] = f1_score(y_test, y_pred, average='weighted')\n",
    "    metrics['confusion_matrix'] = confusion_matrix(y_test, y_pred)\n",
    "    metrics['mcc'] = matthews_corrcoef(y_test, y_pred)\n",
    "    metrics['classification_report'] = classification_report(y_test, y_pred)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Prints all performance metrics\n",
    "def print_performance_metrics(metrics):\n",
    "    print(\"Accuracy:\", metrics.get('accuracy', \"Not computed\"))\n",
    "    print(\"Precision:\", metrics.get('precision', \"Not computed\"))\n",
    "    print(\"Recall:\", metrics.get('recall', \"Not computed\"))\n",
    "    print(\"F1 Score:\", metrics.get('f1_score', \"Not computed\"))\n",
    "    print(\"Confusion Matrix:\\n\", metrics.get('confusion_matrix', \"Not computed\"))\n",
    "    print(\"Matthews Correlation Coefficient (MCC):\", metrics.get('mcc', \"Not computed\"))\n",
    "    print(\"Classification Report:\\n\", metrics.get('classification_report', \"Not computed\"))\n",
    "\n",
    "# Determine the feature importance in the model\n",
    "def feature_importance(model, X, feature_names):\n",
    "    feature_importances = model.feature_importances_\n",
    "    feature_importances_list = [(feature_names[j], importance) for j, importance in enumerate(feature_importances)]\n",
    "    feature_importances_list.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"Feature Importances:\")\n",
    "    for feature, importance in feature_importances_list:\n",
    "        print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b37816b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains the model\n",
    "def create_model():\n",
    "    # Load the data\n",
    "    data_name = ''\n",
    "    processed_data = pd.read_csv(\"./data/final.csv\")\n",
    "    processed_data = processed_data.drop(columns=[\"date\"])\n",
    "\n",
    "\n",
    "    # Separate data\n",
    "    target_name = 'weather_code'\n",
    "    X = processed_data.drop(columns=[target_name]).values\n",
    "    y = processed_data[target_name].values\n",
    "\n",
    "    # feature_names = processed_data.columns[:-1].tolist()\n",
    "    feature_names = processed_data.drop(columns=[target_name]).columns.tolist()\n",
    "\n",
    "    # Get test and train\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    print('Read the data')\n",
    "    # Run the model\n",
    "    model = train_model(X_train, y_train, X_test, y_test, feature_names)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f0ded18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.898936170212766\n",
      "Precision: 0.8989454973203981\n",
      "Recall: 0.898936170212766\n",
      "F1 Score: 0.8963586944927425\n",
      "Confusion Matrix:\n",
      " [[ 33   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0  37   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   1  33   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   1   0   0  43   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  26   3   1   0   1   0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   4   9   0   0   1   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   2   2   0   2   1   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   2   0  11   3   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   8  12   1   0   0   0   0   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   4   7   0   0   0   0   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   0   0   7   1   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  36   2   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   8   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   0   2   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   1   0   0   0   0   0   1]]\n",
      "Matthews Correlation Coefficient (MCC): 0.871877805371131\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97        34\n",
      "         1.0       0.93      0.97      0.95        38\n",
      "         2.0       0.97      0.97      0.97        34\n",
      "         3.0       1.00      1.00      1.00       240\n",
      "        45.0       1.00      0.98      0.99        44\n",
      "        51.0       0.81      0.81      0.81        32\n",
      "        53.0       0.64      0.64      0.64        14\n",
      "        55.0       0.40      0.25      0.31         8\n",
      "        57.0       0.00      0.00      0.00         1\n",
      "        61.0       0.44      0.69      0.54        16\n",
      "        63.0       0.52      0.52      0.52        23\n",
      "        65.0       0.78      0.54      0.64        13\n",
      "        67.0       0.00      0.00      0.00         1\n",
      "        71.0       0.78      0.78      0.78         9\n",
      "        73.0       0.90      0.95      0.92        38\n",
      "        75.0       0.80      0.73      0.76        11\n",
      "        81.0       0.50      0.40      0.44         5\n",
      "        95.0       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.90       564\n",
      "   macro avg       0.69      0.64      0.65       564\n",
      "weighted avg       0.90      0.90      0.90       564\n",
      "\n",
      "Feature Importances:\n",
      "cloud_cover_max: 0.1278292915103203\n",
      "precipitation_sum: 0.08578589358628419\n",
      "visibility_min: 0.08128258802868485\n",
      "precipitation_hours: 0.07577313421771238\n",
      "cloud_cover_mean: 0.07528268372206837\n",
      "rain_sum: 0.06457559668579249\n",
      "snowfall_water_equivalent_sum: 0.032292495052295124\n",
      "snowfall_sum: 0.028786499354443107\n",
      "visibility_mean: 0.016699022192536855\n",
      "sunshine_duration: 0.013805617016441826\n",
      "relative_humidity_2m_mean: 0.01319528769294664\n",
      "relative_humidity_2m_max: 0.01298978902717483\n",
      "wet_bulb_temperature_2m_max: 0.011861005965023382\n",
      "wet_bulb_temperature_2m_mean: 0.010795657153672405\n",
      "apparent_temperature_mean: 0.01078089236148755\n",
      "dew_point_2m_mean: 0.010633541003184636\n",
      "dew_point_2m_max: 0.01039877883764379\n",
      "temperature_2m_max: 0.0097727841653266\n",
      "vapour_pressure_deficit_max: 0.009644671057922542\n",
      "cape_max: 0.009545290714393055\n",
      "temperature_2m_mean: 0.009494681009066199\n",
      "temperature_2m_min: 0.009471010376414733\n",
      "apparent_temperature_max: 0.009362369120975919\n",
      "shortwave_radiation_sum: 0.009165962957616786\n",
      "relative_humidity_2m_min: 0.009013781658280205\n",
      "et0_fao_evapotranspiration: 0.008743454877898727\n",
      "apparent_temperature_min: 0.008636997457072904\n",
      "surface_pressure_mean: 0.008494886481980601\n",
      "visibility_max: 0.008466752487058941\n",
      "wind_direction_10m_dominant: 0.00838855101719601\n",
      "dew_point_2m_min: 0.008326623412759044\n",
      "et0_fao_evapotranspiration_sum: 0.00830476363622121\n",
      "daylight_duration: 0.008236327013717156\n",
      "winddirection_10m_dominant: 0.008162283263740659\n",
      "pressure_msl_mean: 0.008114586146674388\n",
      "wind_gusts_10m_mean: 0.008082424744533414\n",
      "surface_pressure_min: 0.008051731376548708\n",
      "wind_speed_10m_mean: 0.008035550385550948\n",
      "pressure_msl_min: 0.008018740413159621\n",
      "wind_gusts_10m_min: 0.007871442333210424\n",
      "wet_bulb_temperature_2m_min: 0.007857807509499557\n",
      "wind_gusts_10m_max: 0.007625011172267371\n",
      "wind_speed_10m_max: 0.007524941806872846\n",
      "cape_mean: 0.007492335327006407\n",
      "wind_speed_10m_min: 0.007488854634153851\n",
      "year_sin: 0.007242114868092571\n",
      "surface_pressure_max: 0.007144694698139106\n",
      "day_of_year: 0.007129411947904246\n",
      "year_cos: 0.007123202456520145\n",
      "day_of_month: 0.007056250879050335\n",
      "year: 0.0069902680664956805\n",
      "pressure_msl_max: 0.006935265179761856\n",
      "uv_index_max: 0.006033867471038873\n",
      "uv_index_clear_sky_max: 0.005722041119268486\n",
      "day_of_week: 0.00400938654255579\n",
      "soil_moisture_0_to_10cm_mean: 0.003076409325024238\n",
      "month: 0.0029817991137373345\n",
      "month_sin: 0.002746590414730281\n",
      "cloud_cover_min: 0.00269347693570818\n",
      "month_cos: 0.002316728427042217\n",
      "cape_min: 0.0006361025900991634\n",
      "showers_sum: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "/mnt/c/Users/Moham/OneDrive/Documents/GitHub/MLOps-Project/ENV/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/mnt/c/Users/Moham/OneDrive/Documents/GitHub/MLOps-Project/ENV/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/mnt/c/Users/Moham/OneDrive/Documents/GitHub/MLOps-Project/ENV/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/mnt/c/Users/Moham/OneDrive/Documents/GitHub/MLOps-Project/ENV/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Runs the model\n",
    "def run_model_training():\n",
    "    # Train the model\n",
    "    create_model()\n",
    "\n",
    "run_model_training()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
